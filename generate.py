# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DUaXdbJFrHR8KVt5tpZhGLIOsrXF1jEv
"""

import argparse
import os
import torch
import torch.nn.functional as F
import numpy as np

class CharDataset:
    def __init__(self, chars):
        self.chars = sorted(set(chars))
        self.char_to_index = {ch: i for i, ch in enumerate(self.chars)}
        self.index_to_char = {i: ch for i, ch in enumerate(self.chars)}
        self.input_size = len(self.chars)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class CharRNN(nn.Module):
    def __init__(self, input_size, hidden_dim):
        super(CharRNN, self).__init__()
        self.input_size = input_size
        self.hidden_dim = hidden_dim

        self.embed = nn.Embedding(input_size, hidden_dim)
        self.RNN = nn.RNN(input_size=hidden_dim, hidden_size=hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, self.input_size)

    def forward(self, input, hidden):
        embedded = self.embed(input)
        output, hidden = self.RNN(embedded, hidden)
        output = output.contiguous().view(-1, self.hidden_dim)
        output = self.fc(output)
        return output, hidden

    def init_hidden(self, batch_size):
        initial_hidden = torch.zeros(1, batch_size, self.hidden_dim)
        return initial_hidden

class CharLSTM(nn.Module):
    def __init__(self, input_size, hidden_dim):
        super(CharLSTM, self).__init__()
        self.input_size = input_size
        self.hidden_dim = hidden_dim
        self.embed = nn.Embedding(input_size, hidden_dim)
        self.LSTM = nn.LSTM(input_size=hidden_dim, hidden_size=hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, input_size)

    def forward(self, input, hidden):
        embedded = self.embed(input)
        output, hidden = self.LSTM(embedded, hidden)
        output = output.contiguous().view(-1, self.hidden_dim)
        output = self.fc(output)
        return output, hidden

    def init_hidden(self, batch_size):
        initial_hidden = (
            torch.zeros(1, batch_size, self.hidden_dim),
            torch.zeros(1, batch_size, self.hidden_dim)
        )
        return initial_hidden

def generate(model, dataset, device, seed_characters, temperature, num_chars):
    model.eval()
    hidden = model.init_hidden(1)
    samples = seed_characters

    x = torch.tensor([dataset.char_to_index[char] for char in seed_characters], dtype=torch.long).to(device)

    for _ in range(num_chars):
        x = x.view(1, -1)
        output, hidden = model(x, hidden)
        output = output[-1]
        pred = F.softmax(output / temperature, dim=-1).detach().cpu().numpy()
        next_char_idx = np.random.choice(dataset.input_size, p=pred)
        next_char = dataset.index_to_char[next_char_idx]
        samples += next_char
        x = torch.tensor([next_char_idx], dtype=torch.long).to(device)

    return samples

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--seed', type=str, required=True)
    parser.add_argument('--temp', type=float, default=0.5)
    parser.add_argument('--num_chars', type=int, default=100)
    parser.add_argument('--model_name', type=str, required=True)
    args = parser.parse_args()

    seed_characters = args.seed
    temperature = args.temp
    num_chars = args.num_chars
    model_name = args.model_name

    hidden_dim = 128  # Ensure this matches the hidden_dim used in main.py

    if model_name == 'RNN':
        model = CharRNN(input_size=len(datasets.chars), hidden_dim=hidden_dim)
    elif model_name == 'LSTM':
        model = CharLSTM(input_size=len(datasets.chars), hidden_dim=hidden_dim)

    model.to(device)

    model_save_dir = './model'
    if not os.path.exists(model_save_dir):
        os.makedirs(model_save_dir)

    model_path = os.path.join(model_save_dir, f'{model_name}.pth')
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Model file not found: {model_path}")

    model.load_state_dict(torch.load(model_path, map_location=device))

    generated_text = generate(model=model, dataset=datasets, device=device, seed_characters=seed_characters, temperature=temperature, num_chars=num_chars)
    print(generated_text)